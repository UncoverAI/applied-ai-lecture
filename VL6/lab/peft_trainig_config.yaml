dataset: HuggingFaceM4/ChartQA
num_proc: 16
model:
  model_id: Qwen/Qwen2-VL-7B-Instruct
  device_map: auto
  torch_dtype: bfloat16
  max_tokens: 1024
  quant_config:
    load_in_4bit: true
  lora_config:
    lora_alpha: 16
    lora_dropout: 0.05
    r: 8
args:
  output_dir: tuned_qwen
  num_train_epochs: 1
  per_device_train_batch_size: 2
  per_device_eval_batch_size: 2
  gradient_accumulation_steps: 2
  optim: adamw_torch_fused
  learning_rate: 0.0002
  lr_scheduler_type: constant
  logging_steps: 2
  eval_steps: 8
  eval_strategy: steps
  save_strategy: 'no'
  bf16: true
