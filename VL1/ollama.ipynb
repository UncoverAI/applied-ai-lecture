{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'models': [{'name': 'nomic-embed-text:latest',\n",
       "   'model': 'nomic-embed-text:latest',\n",
       "   'modified_at': '2024-09-20T19:37:25.3504775+02:00',\n",
       "   'size': 274302450,\n",
       "   'digest': '0a109f422b47e3a30ba2b10eca18548e944e8a23073ee3f3e947efcf3c45e59f',\n",
       "   'details': {'parent_model': '',\n",
       "    'format': 'gguf',\n",
       "    'family': 'nomic-bert',\n",
       "    'families': ['nomic-bert'],\n",
       "    'parameter_size': '137M',\n",
       "    'quantization_level': 'F16'}},\n",
       "  {'name': 'codestral:latest',\n",
       "   'model': 'codestral:latest',\n",
       "   'modified_at': '2024-09-20T19:34:45.1339781+02:00',\n",
       "   'size': 12569170438,\n",
       "   'digest': '0898a8b286d56d8105587049fec69634fce83c957230fc13f0acfe03b7b11909',\n",
       "   'details': {'parent_model': '',\n",
       "    'format': 'gguf',\n",
       "    'family': 'llama',\n",
       "    'families': ['llama'],\n",
       "    'parameter_size': '22.2B',\n",
       "    'quantization_level': 'Q4_0'}},\n",
       "  {'name': 'llama3.1:8b-instruct-q4_0',\n",
       "   'model': 'llama3.1:8b-instruct-q4_0',\n",
       "   'modified_at': '2024-08-10T13:05:55.8302269+02:00',\n",
       "   'size': 4661230977,\n",
       "   'digest': '91ab477bec9d27086a119e33c471ae7afbd786cc4fbd8f38d8af0a0b949d53aa',\n",
       "   'details': {'parent_model': '',\n",
       "    'format': 'gguf',\n",
       "    'family': 'llama',\n",
       "    'families': ['llama'],\n",
       "    'parameter_size': '8.0B',\n",
       "    'quantization_level': 'Q4_0'}},\n",
       "  {'name': 'llama3.1:8b-instruct-fp16',\n",
       "   'model': 'llama3.1:8b-instruct-fp16',\n",
       "   'modified_at': '2024-08-04T13:39:44.1904459+02:00',\n",
       "   'size': 16068905889,\n",
       "   'digest': '9d95e89188d4315cedc62d969a7b4257cce295797013044c4094823c3ced502f',\n",
       "   'details': {'parent_model': '',\n",
       "    'format': 'gguf',\n",
       "    'family': 'llama',\n",
       "    'families': ['llama'],\n",
       "    'parameter_size': '8.0B',\n",
       "    'quantization_level': 'F16'}}]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ollama.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'success'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_ID = 'llama3.1:8b-instruct-q4_0'\n",
    "ollama.pull(MODEL_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.1:8b-instruct-q4_0', 'created_at': '2024-10-18T17:28:39.09393Z', 'response': 'I\\'m an artificial intelligence model known as Llama. Llama stands for \"Large Language Model Meta AI.\"', 'done': True, 'done_reason': 'stop', 'context': [128006, 882, 128007, 271, 9906, 11, 889, 527, 499, 30, 128009, 128006, 78191, 128007, 271, 40, 2846, 459, 21075, 11478, 1646, 3967, 439, 445, 81101, 13, 445, 81101, 13656, 369, 330, 35353, 11688, 5008, 16197, 15592, 1210], 'total_duration': 82668465400, 'load_duration': 82368142100, 'prompt_eval_count': 16, 'prompt_eval_duration': 30763000, 'eval_count': 23, 'eval_duration': 266582000}\n",
      "I'm an artificial intelligence model known as Llama. Llama stands for \"Large Language Model Meta AI.\"\n"
     ]
    }
   ],
   "source": [
    "response = ollama.generate(model=MODEL_ID, prompt=\"Hello, who are you?\")\n",
    "print(response)\n",
    "print(response['response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat with Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.1:8b-instruct-q4_0', 'created_at': '2024-10-18T17:30:57.4832181Z', 'message': {'role': 'assistant', 'content': 'I\\'m an artificial intelligence model known as Llama. Llama stands for \"Large Language Model Meta AI.\"'}, 'done_reason': 'stop', 'done': True, 'total_duration': 62032462100, 'load_duration': 61689814200, 'prompt_eval_count': 16, 'prompt_eval_duration': 29471000, 'eval_count': 23, 'eval_duration': 311519000}\n",
      "I'm an artificial intelligence model known as Llama. Llama stands for \"Large Language Model Meta AI.\"\n"
     ]
    }
   ],
   "source": [
    "response = ollama.chat(model=MODEL_ID, messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Hello, who are you?',\n",
    "  },\n",
    "])\n",
    "print(response)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.1:8b-instruct-q4_0', 'created_at': '2024-10-18T17:29:23.4039413Z', 'message': {'role': 'assistant', 'content': 'Ich bin ein Computer-Programm, das darauf programmiert ist, Fragen zu beantworten und Gespr채che zu f체hren. Ich bin kein Mensch, sondern eine KI, die in der Lage ist, auf Deutsch zu sprechen und zu denken. Wie geht es Ihnen heute?'}, 'done_reason': 'stop', 'done': True, 'total_duration': 16002034500, 'load_duration': 15225113100, 'prompt_eval_count': 35, 'prompt_eval_duration': 33838000, 'eval_count': 62, 'eval_duration': 740552000}\n",
      "Ich bin ein Computer-Programm, das darauf programmiert ist, Fragen zu beantworten und Gespr채che zu f체hren. Ich bin kein Mensch, sondern eine KI, die in der Lage ist, auf Deutsch zu sprechen und zu denken. Wie geht es Ihnen heute?\n"
     ]
    }
   ],
   "source": [
    "response = ollama.chat(model=MODEL_ID, messages=[\n",
    "  {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ALWAYS ANSWER IN GERMAN, NO MATTER THE QUESTION!\"\n",
    "  },\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Hello, who are you?',\n",
    "  },\n",
    "])\n",
    "print(response)\n",
    "print(response['message']['content'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uncoverai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
