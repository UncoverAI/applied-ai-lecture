{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'models': [{'name': 'nomic-embed-text:latest',\n",
       "   'model': 'nomic-embed-text:latest',\n",
       "   'modified_at': '2024-09-20T19:37:25.3504775+02:00',\n",
       "   'size': 274302450,\n",
       "   'digest': '0a109f422b47e3a30ba2b10eca18548e944e8a23073ee3f3e947efcf3c45e59f',\n",
       "   'details': {'parent_model': '',\n",
       "    'format': 'gguf',\n",
       "    'family': 'nomic-bert',\n",
       "    'families': ['nomic-bert'],\n",
       "    'parameter_size': '137M',\n",
       "    'quantization_level': 'F16'}},\n",
       "  {'name': 'codestral:latest',\n",
       "   'model': 'codestral:latest',\n",
       "   'modified_at': '2024-09-20T19:34:45.1339781+02:00',\n",
       "   'size': 12569170438,\n",
       "   'digest': '0898a8b286d56d8105587049fec69634fce83c957230fc13f0acfe03b7b11909',\n",
       "   'details': {'parent_model': '',\n",
       "    'format': 'gguf',\n",
       "    'family': 'llama',\n",
       "    'families': ['llama'],\n",
       "    'parameter_size': '22.2B',\n",
       "    'quantization_level': 'Q4_0'}},\n",
       "  {'name': 'llama3.1:8b-instruct-q4_0',\n",
       "   'model': 'llama3.1:8b-instruct-q4_0',\n",
       "   'modified_at': '2024-08-10T13:05:55.8302269+02:00',\n",
       "   'size': 4661230977,\n",
       "   'digest': '91ab477bec9d27086a119e33c471ae7afbd786cc4fbd8f38d8af0a0b949d53aa',\n",
       "   'details': {'parent_model': '',\n",
       "    'format': 'gguf',\n",
       "    'family': 'llama',\n",
       "    'families': ['llama'],\n",
       "    'parameter_size': '8.0B',\n",
       "    'quantization_level': 'Q4_0'}},\n",
       "  {'name': 'llama3.1:8b-instruct-fp16',\n",
       "   'model': 'llama3.1:8b-instruct-fp16',\n",
       "   'modified_at': '2024-08-04T13:39:44.1904459+02:00',\n",
       "   'size': 16068905889,\n",
       "   'digest': '9d95e89188d4315cedc62d969a7b4257cce295797013044c4094823c3ced502f',\n",
       "   'details': {'parent_model': '',\n",
       "    'format': 'gguf',\n",
       "    'family': 'llama',\n",
       "    'families': ['llama'],\n",
       "    'parameter_size': '8.0B',\n",
       "    'quantization_level': 'F16'}}]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ollama.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'success'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_ID = 'llama3.1:8b-instruct-q4_0'\n",
    "ollama.pull(MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ollama.generate(model=MODEL_ID, prompt=\"Hello, who are you?\")\n",
    "print(response)\n",
    "print(response['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm an artificial intelligence model known as Llama. Llama stands for \"Large Language Model Meta AI.\"\n"
     ]
    }
   ],
   "source": [
    "response = ollama.chat(model=MODEL_ID, messages=[\n",
    "  {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"ALWAYS ANSWER IN GERMAN, NO MATTER THE QUESTION!\"\n",
    "  },\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Hello, who are you?',\n",
    "  },\n",
    "])\n",
    "print(response)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'llama3.1:8b-instruct-q4_0',\n",
       " 'created_at': '2024-10-18T16:59:43.8382186Z',\n",
       " 'message': {'role': 'assistant',\n",
       "  'content': 'I\\'m an artificial intelligence model known as Llama. Llama stands for \"Large Language Model Meta AI.\"'},\n",
       " 'done_reason': 'stop',\n",
       " 'done': True,\n",
       " 'total_duration': 38790671700,\n",
       " 'load_duration': 38485902800,\n",
       " 'prompt_eval_count': 16,\n",
       " 'prompt_eval_duration': 30856000,\n",
       " 'eval_count': 23,\n",
       " 'eval_duration': 272212000}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.7906717"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"total_duration\"] / 10**9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uncoverai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
